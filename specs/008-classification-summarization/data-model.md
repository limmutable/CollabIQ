# Data Model: Classification & Summarization

**Feature**: 008-classification-summarization
**Date**: 2025-11-03
**Phase**: Phase 1 - Design Artifacts

## Overview

This document defines the data structures for Phase 2c classification and summarization. All models extend existing Phase 1b (ExtractedEntities) and Phase 2b (company matching) schemas to maintain backward compatibility.

---

## Entity Definitions

### 1. Collaboration Classification

**Purpose**: Represents the categorization result for a collaboration (type + intensity + confidence scores).

**Source**: Derived from Phase 2b matched company classifications (`matched_company_id` + `matched_partner_id`) and Gemini LLM analysis.

```python
from pydantic import BaseModel, Field
from typing import Optional

class CollaborationClassification(BaseModel):
    """Classification result for collaboration type and intensity"""

    collaboration_type: Optional[str] = Field(
        None,
        description="Exact Notion field value (e.g., '[A]PortCoXSSG', '[B]Non-PortCoXSSG', '[C]PortCoXPortCo', '[D]Other')",
        pattern=r'^\[([A-Z0-9])\].*$'
    )

    collaboration_intensity: Optional[str] = Field(
        None,
        description="Korean intensity level: 이해, 협력, 투자, 인수",
        pattern=r'^(이해|협력|투자|인수)$'
    )

    type_confidence: Optional[float] = Field(
        None,
        ge=0.0,
        le=1.0,
        description="Confidence score for type classification (0.0-1.0)"
    )

    intensity_confidence: Optional[float] = Field(
        None,
        ge=0.0,
        le=1.0,
        description="Confidence score for intensity classification (0.0-1.0)"
    )

    classification_reason: Optional[str] = Field(
        None,
        description="Explanation for why this classification was chosen (debugging/monitoring)"
    )
```

**Validation Rules**:
- `collaboration_type`: Must match `[X]*` pattern where X is code (A/B/C/D or 1/2/3/4)
- `collaboration_intensity`: Must be one of 4 exact Korean values (이해/협력/투자/인수)
- `type_confidence` and `intensity_confidence`: Must be in range [0.0, 1.0]
- All fields optional (nullable) for graceful degradation if classification fails

**Relationships**:
- **Input**: `matched_company_id` (Phase 2b) + `matched_partner_id` (Phase 2b)
- **Output**: Used by Phase 2d (Notion Write Operations) to populate CollabIQ database

---

### 2. Collaboration Summary

**Purpose**: Structured summary preserving 5 key entities (startup, partner, activity, date, person).

**Source**: Generated by Gemini LLM from cleaned email content (Phase 1a output).

```python
class CollaborationSummary(BaseModel):
    """Structured summary of collaboration content"""

    summary_text: Optional[str] = Field(
        None,
        description="3-5 sentence summary in Korean (50-150 words)",
        min_length=50,
        max_length=750  # ~150 words * 5 chars/word
    )

    word_count: Optional[int] = Field(
        None,
        ge=50,
        le=150,
        description="Actual word count (for validation)"
    )

    key_entities_preserved: Optional[dict] = Field(
        None,
        description="Boolean flags for which key entities were preserved"
    )

    summary_language: Optional[str] = Field(
        None,
        pattern=r'^(Korean|English|Mixed)$',
        description="Primary language of summary"
    )

class KeyEntitiesPreserved(BaseModel):
    """Checklist of which key entities are present in summary"""
    startup: bool = Field(description="Startup name preserved?")
    partner: bool = Field(description="Partner organization preserved?")
    activity: bool = Field(description="Activity/purpose preserved?")
    date: bool = Field(description="Date preserved?")
    person: bool = Field(description="Person in charge preserved?")
```

**Validation Rules**:
- `summary_text`: Min 50 chars, max 750 chars (~150 words * 5 chars/word average)
- `word_count`: Must be in range [50, 150]
- `key_entities_preserved`: Boolean checklist for 5 required entities
- `summary_language`: Must be "Korean", "English", or "Mixed"

**Success Criteria** (from spec.md):
- SC-003: ≥90% of summaries preserve all 5 key entities when present in original email
- SC-004: ≥95% of summaries stay within 50-150 word range

**Relationships**:
- **Input**: Cleaned email content (Phase 1a) + Extracted entities (Phase 1b)
- **Output**: Displayed in Notion database for quick review

---

### 3. Extended Extracted Entities

**Purpose**: Extends Phase 1b `ExtractedEntities` model with Phase 2c classification and summarization fields.

**Backward Compatibility**: All new fields are optional (nullable) so Phase 1b/2b extraction continues to work without Phase 2c.

```python
from typing import Optional
from pydantic import BaseModel, Field

# Existing Phase 1b + Phase 2b model (not modified)
class ExtractedEntities(BaseModel):
    """Phase 1b entity extraction + Phase 2b company matching"""
    담당자: Optional[str] = None
    스타트업명: Optional[str] = None
    협업기관: Optional[str] = None
    협업내용: Optional[str] = None
    날짜: Optional[str] = None

    # Phase 2b additions
    matched_company_id: Optional[str] = None
    matched_partner_id: Optional[str] = None
    company_confidence: Optional[float] = None
    partner_confidence: Optional[float] = None

# Phase 2c extension (NEW)
class ExtractedEntitiesWithClassification(ExtractedEntities):
    """Extended model with Phase 2c classification and summarization"""

    # Classification fields
    collaboration_type: Optional[str] = Field(
        None,
        description="Exact Notion field value from 협업형태 property"
    )

    collaboration_intensity: Optional[str] = Field(
        None,
        description="Intensity level: 이해, 협력, 투자, 인수"
    )

    type_confidence: Optional[float] = Field(
        None,
        ge=0.0,
        le=1.0,
        description="Type classification confidence"
    )

    intensity_confidence: Optional[float] = Field(
        None,
        ge=0.0,
        le=1.0,
        description="Intensity classification confidence"
    )

    # Summary fields
    collaboration_summary: Optional[str] = Field(
        None,
        description="3-5 sentence summary (50-150 words)"
    )

    summary_word_count: Optional[int] = Field(
        None,
        description="Summary word count for validation"
    )

    key_entities_preserved: Optional[dict] = Field(
        None,
        description="Which key entities are in summary"
    )

    # Metadata
    classification_timestamp: Optional[str] = Field(
        None,
        description="ISO 8601 timestamp of classification"
    )
```

**Backward Compatibility Strategy**:
- ✅ All Phase 2c fields are `Optional` (nullable)
- ✅ Inherits from existing `ExtractedEntities` (no breaking changes)
- ✅ Phase 1b/2b code can continue using base `ExtractedEntities` model
- ✅ Phase 2c code uses `ExtractedEntitiesWithClassification` model
- ✅ JSON serialization preserves all fields (old + new)

**Migration Path**:
```python
# Phase 1b/2b code (unchanged)
entities = gemini_adapter.extract_entities(email_content)  # Returns ExtractedEntities

# Phase 2c code (extends)
entities_with_classification = gemini_adapter.extract_entities_with_classification(email_content)  # Returns ExtractedEntitiesWithClassification
```

---

## Data Flow

### Classification Flow

```
Input:
  ├── Cleaned Email (Phase 1a)
  ├── ExtractedEntities (Phase 1b: 담당자, 스타트업명, 협업기관, 협업내용, 날짜)
  └── Company Matching (Phase 2b: matched_company_id, matched_partner_id)

Processing:
  ├── Step 1: Fetch "협업형태" values from Notion (NotionIntegrator.discover_database_schema)
  ├── Step 2: Classify type (deterministic logic based on company classifications)
  ├── Step 3: Classify intensity (Gemini LLM with Korean prompt)
  └── Step 4: Generate summary (Gemini LLM with entity preservation)

Output:
  └── ExtractedEntitiesWithClassification
      ├── All Phase 1b+2b fields (preserved)
      ├── collaboration_type (e.g., "[A]PortCoXSSG")
      ├── collaboration_intensity (e.g., "협력")
      ├── type_confidence (e.g., 0.92)
      ├── intensity_confidence (e.g., 0.88)
      ├── collaboration_summary (3-5 sentences)
      └── key_entities_preserved (boolean flags)
```

### Storage Format

**File Location**: `data/extractions/{email_id}.json`

**JSON Schema**:
```json
{
  "담당자": "김주영",
  "스타트업명": "브레이크앤컴퍼니",
  "협업기관": "신세계푸드",
  "협업내용": "AI 기반 재고 최적화 솔루션 PoC",
  "날짜": "2025-10-28",

  "matched_company_id": "uuid-123",
  "matched_partner_id": "uuid-456",
  "company_confidence": 0.95,
  "partner_confidence": 0.98,

  "collaboration_type": "[A]PortCoXSSG",
  "collaboration_intensity": "협력",
  "type_confidence": 0.92,
  "intensity_confidence": 0.88,

  "collaboration_summary": "브레이크앤컴퍼니와 신세계푸드가 AI 기반 재고 최적화 솔루션 PoC 킥오프 미팅을 진행했습니다. 신세계백화점 강남점에서 11월 첫째 주부터 2개월간 파일럿 테스트 예정이며, 재고 회전율 15% 개선 및 폐기 손실 20% 감소 효과가 기대됩니다. 김주영 담당자가 프로젝트를 주도하며, 11월 3일 기술 통합 회의가 예정되어 있습니다.",
  "summary_word_count": 78,
  "key_entities_preserved": {
    "startup": true,
    "partner": true,
    "activity": true,
    "date": true,
    "person": true
  },

  "classification_timestamp": "2025-11-03T10:30:00Z"
}
```

---

## Validation & Constraints

### Model-Level Validation (Pydantic)

```python
from pydantic import validator

class ExtractedEntitiesWithClassification(ExtractedEntities):
    # ... field definitions ...

    @validator('collaboration_type')
    def validate_type_format(cls, v):
        """Ensure type follows [X]* pattern"""
        if v is not None:
            import re
            if not re.match(r'^\[([A-Z0-9])\]', v):
                raise ValueError(f"Invalid collaboration_type format: {v}")
        return v

    @validator('collaboration_intensity')
    def validate_intensity(cls, v):
        """Ensure intensity is one of 4 valid values"""
        if v is not None:
            valid = ['이해', '협력', '투자', '인수']
            if v not in valid:
                raise ValueError(f"Invalid collaboration_intensity: {v}, must be one of {valid}")
        return v

    @validator('summary_word_count')
    def validate_word_count(cls, v, values):
        """Verify word count matches summary length"""
        if v is not None and 'collaboration_summary' in values:
            summary = values['collaboration_summary']
            if summary:
                actual_count = len(summary.split())
                if abs(actual_count - v) > 5:  # Allow 5-word tolerance
                    raise ValueError(f"Word count mismatch: reported {v}, actual {actual_count}")
        return v
```

### Business Logic Validation

```python
def validate_classification_completeness(entities: ExtractedEntitiesWithClassification) -> dict:
    """Validate classification meets success criteria"""
    issues = []

    # SC-001: Type classification required
    if entities.collaboration_type is None:
        issues.append("Missing collaboration_type")

    # SC-002: Intensity classification required
    if entities.collaboration_intensity is None:
        issues.append("Missing collaboration_intensity")

    # SC-003: Key entities preserved (≥90%)
    if entities.key_entities_preserved:
        preserved_count = sum(entities.key_entities_preserved.values())
        if preserved_count < 4:  # Allow 1 missing entity
            issues.append(f"Only {preserved_count}/5 key entities preserved")

    # SC-004: Summary word count in range
    if entities.summary_word_count:
        if not (50 <= entities.summary_word_count <= 150):
            issues.append(f"Summary word count out of range: {entities.summary_word_count}")

    # SC-005: Confidence scores predict accuracy
    if entities.type_confidence and entities.type_confidence < 0.85:
        issues.append(f"Low type confidence: {entities.type_confidence} < 0.85")

    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "needs_manual_review": any(
            conf and conf < 0.85
            for conf in [entities.type_confidence, entities.intensity_confidence]
            if conf is not None
        )
    }
```

---

## Schema Migration

### Phase 2b → Phase 2c Migration

**No breaking changes required** - all new fields are optional.

**Existing extraction files** (`data/extractions/*.json`):
- ✅ Continue to work without modification
- ✅ Phase 2c processing adds new fields on next run
- ✅ Old extractions can be re-processed to add classifications

**Re-processing Strategy** (if needed):
```python
def upgrade_extraction_file(file_path: str):
    """Add Phase 2c classifications to existing extraction"""
    with open(file_path) as f:
        data = json.load(f)

    # Parse as Phase 1b/2b model
    entities = ExtractedEntities(**data)

    # Run Phase 2c classification
    classification_service = ClassificationService(...)
    entities_with_classification = await classification_service.classify(entities)

    # Save upgraded version
    with open(file_path, 'w') as f:
        json.dump(entities_with_classification.dict(), f, ensure_ascii=False, indent=2)
```

---

## Summary

**New Models**:
1. `CollaborationClassification` - Type + intensity + confidence
2. `CollaborationSummary` - 3-5 sentence summary with entity checklist
3. `ExtractedEntitiesWithClassification` - Extended Phase 1b/2b model

**Key Properties**:
- ✅ All new fields optional (backward compatible)
- ✅ Pydantic validation for data integrity
- ✅ JSON serialization for file storage
- ✅ No database schema changes (file-based storage)

**Validation Coverage**:
- ✅ Model-level (Pydantic validators)
- ✅ Business logic (success criteria checks)
- ✅ Manual review routing (confidence threshold)

**Next Steps**: Generate API contracts (contracts/gemini_adapter_extension.md)
