# LLM Provider API Contract

version: "1.0.0"
feature: "004-gemini-extraction"
date: "2025-11-01"

# Abstract Interface: LLMProvider
#
# This contract defines the abstract interface that all LLM adapters must implement.
# Currently implemented by: GeminiAdapter (Phase 1b)
# Future implementations: GPT4Adapter, ClaudeAdapter

---

## LLMProvider (Abstract Base Class)

### Purpose
Enable swapping between different LLM providers (Gemini, GPT, Claude) without rewriting business logic.

### Methods

#### `extract_entities(email_text: str) -> ExtractedEntities`

**Description**: Extract 5 key entities from email text with confidence scores.

**Input Parameters**:
- `email_text` (string, required): Cleaned email body (Korean/English/mixed)
  - Constraints: Non-empty string, max 10,000 characters
  - Preprocessing: Signatures, disclaimers, quoted text already removed (by Phase 1a ContentNormalizer)
  - Example: `"어제 신세계인터와 본봄 파일럿 킥오프, 11월 1주 PoC 시작 예정"`

**Output**:
- `ExtractedEntities` (object): Pydantic model with 5 entities + confidence scores
  - See data-model.md for full schema
  - All fields are optional except `confidence`, `email_id`, `extracted_at`

**Errors**:
- `LLMAPIError`: Base exception for all LLM API errors
  - Attributes: `message`, `status_code`, `original_error`
  - When raised: API call fails for any reason

- `LLMRateLimitError` (subclass of LLMAPIError): Rate limit exceeded
  - HTTP Status: 429 (RESOURCE_EXHAUSTED)
  - Retry Strategy: Exponential backoff (caller's responsibility)
  - When raised: API returns rate limit error

- `LLMTimeoutError` (subclass of LLMAPIError): Request timeout
  - Timeout: Configurable (default 10 seconds)
  - Retry Strategy: Retry once with increased timeout
  - When raised: API doesn't respond within timeout

- `LLMAuthenticationError` (subclass of LLMAPIError): Authentication failed
  - HTTP Status: 401, 403
  - Retry Strategy: No retry (requires fix)
  - When raised: Invalid API key or insufficient permissions

**Contract Test Cases**:
```python
def test_extract_entities_accepts_email_text(llm_provider):
    """Test 1: extract_entities accepts email_text string"""
    result = llm_provider.extract_entities("sample email text")
    assert isinstance(result, ExtractedEntities)

def test_extract_entities_returns_extracted_entities(llm_provider):
    """Test 2: extract_entities returns ExtractedEntities"""
    result = llm_provider.extract_entities("collaboration update email")
    assert hasattr(result, "person_in_charge")
    assert hasattr(result, "startup_name")
    assert hasattr(result, "partner_org")
    assert hasattr(result, "details")
    assert hasattr(result, "date")
    assert hasattr(result, "confidence")

def test_extract_entities_raises_llm_api_error_on_failure(llm_provider):
    """Test 3: extract_entities raises LLMAPIError on API failure"""
    with mock.patch.object(llm_provider, "_call_api", side_effect=Exception("API down")):
        with pytest.raises(LLMAPIError):
            llm_provider.extract_entities("email text")

def test_confidence_scores_are_0_to_1(llm_provider):
    """Test 4: Confidence scores are 0.0-1.0"""
    result = llm_provider.extract_entities("sample email")
    assert 0.0 <= result.confidence.person <= 1.0
    assert 0.0 <= result.confidence.startup <= 1.0
    assert 0.0 <= result.confidence.partner <= 1.0
    assert 0.0 <= result.confidence.details <= 1.0
    assert 0.0 <= result.confidence.date <= 1.0

def test_missing_entities_return_none_with_zero_confidence(llm_provider):
    """Test 5: Missing entities return None + confidence 0.0"""
    result = llm_provider.extract_entities("email with missing person")
    if result.person_in_charge is None:
        assert result.confidence.person == 0.0
```

**Preconditions**:
- API key configured (via environment variable or settings)
- Network connectivity available
- Email text is cleaned (Phase 1a preprocessing)

**Postconditions**:
- Exactly one `ExtractedEntities` object returned (or exception raised)
- All confidence scores are 0.0-1.0
- Missing entities have None value + confidence 0.0
- `email_id` and `extracted_at` are populated

**Side Effects**:
- API request logged (without exposing API key)
- Token usage counted (for cost tracking)
- Optional: Extraction cached in memory (TTL-based)

---

## GeminiAdapter(LLMProvider)

### Purpose
Concrete implementation of LLMProvider using Google Gemini 2.5 Flash API.

### Constructor

```python
GeminiAdapter(
    api_key: str,
    model: str = "gemini-2.5-flash",
    timeout: int = 10,
    max_retries: int = 3
)
```

**Parameters**:
- `api_key` (string, required): Gemini API key from Google AI Studio
  - Source: `GEMINI_API_KEY` environment variable (via settings)
  - Validation: Non-empty string starting with "AIza"

- `model` (string, optional): Gemini model name
  - Default: `"gemini-2.5-flash"`
  - Allowed values: `"gemini-2.5-flash"`, `"gemini-2.5-pro"`
  - Recommendation: Use Flash for cost/speed balance

- `timeout` (int, optional): Request timeout in seconds
  - Default: `10`
  - Range: 5-60 seconds
  - Recommendation: 10 seconds for typical emails

- `max_retries` (int, optional): Maximum retry attempts
  - Default: `3`
  - Range: 0-5
  - Retry strategy: Exponential backoff (1s → 2s → 4s)

### Implementation Details

**Prompt Template**:
- System prompt: Defines extraction task and output schema
- Few-shot examples: 2-3 Korean/English examples for better accuracy
- JSON schema: Structured output with confidence scores

**Response Schema** (Gemini structured output):
```json
{
  "type": "object",
  "properties": {
    "person_in_charge": {
      "type": "object",
      "properties": {
        "value": {"type": ["string", "null"]},
        "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0}
      },
      "required": ["value", "confidence"]
    },
    "startup_name": { "..." },
    "partner_org": { "..." },
    "details": { "..." },
    "date": {
      "type": "object",
      "properties": {
        "value": {"type": ["string", "null"], "format": "date"},
        "confidence": {"type": "number", "minimum": 0.0, "maximum": 1.0}
      },
      "required": ["value", "confidence"]
    }
  },
  "required": ["person_in_charge", "startup_name", "partner_org", "details", "date"]
}
```

**Error Handling**:
- 429 (Rate Limit): Retry with exponential backoff
- 500/503 (Server Error): Retry up to max_retries
- 400/401/403 (Auth Error): Raise LLMAuthenticationError (no retry)
- 408 (Timeout): Retry once with increased timeout

**Retry Logic**:
```python
def _call_with_retry(self, email_text: str) -> dict:
    for attempt in range(self.max_retries):
        try:
            return self._call_gemini_api(email_text)
        except RateLimitError as e:
            if attempt == self.max_retries - 1:
                raise LLMRateLimitError(f"Rate limit exceeded after {self.max_retries} retries") from e
            delay = min(60, (2 ** attempt) + random.uniform(0, 1))
            time.sleep(delay)
        except (InternalServerError, ServiceUnavailable) as e:
            if attempt == self.max_retries - 1:
                raise LLMAPIError(f"API error after {self.max_retries} retries") from e
            delay = min(60, (2 ** attempt))
            time.sleep(delay)
```

### Configuration Example

```python
from src.llm_adapters.gemini_adapter import GeminiAdapter
from src.config.settings import get_settings

settings = get_settings()

# Initialize adapter
llm = GeminiAdapter(
    api_key=settings.get_secret_or_env("GEMINI_API_KEY"),
    model=settings.gemini_model,  # "gemini-2.5-flash"
    timeout=10,
    max_retries=3
)

# Extract entities
email_text = "어제 신세계인터와 본봄 파일럿 킥오프, 11월 1주 PoC 시작 예정"
entities = llm.extract_entities(email_text)

print(entities.model_dump_json(indent=2))
```

---

## Exception Hierarchy

```
Exception
└── LLMAPIError (base exception for all LLM errors)
    ├── LLMRateLimitError (429 - rate limit exceeded)
    ├── LLMTimeoutError (request timeout)
    ├── LLMAuthenticationError (401/403 - auth failed)
    └── LLMValidationError (malformed API response)
```

**Exception Attributes**:
- `message` (str): Human-readable error message
- `status_code` (int | None): HTTP status code (if applicable)
- `original_error` (Exception | None): Original exception that was caught

---

## Performance Guarantees

| Metric | Guarantee | Measurement |
|--------|-----------|-------------|
| **Single Extraction** | ≤5 seconds (excluding API latency) | Process start to ExtractedEntities return |
| **Batch Processing** | No memory leaks on 20 emails | Memory usage stable across batches |
| **API Latency** | ~1-3 seconds typical | Gemini API response time (external) |
| **Token Usage** | ~500-1000 tokens per email | Prompt + response tokens |

---

## Security Requirements

1. **API Key Protection**:
   - MUST NOT log API keys in plaintext
   - MUST use environment variables or secrets management (Infisical)
   - MUST NOT include API keys in error messages

2. **Data Privacy**:
   - Email content sent to Gemini API (Google's privacy policy applies)
   - Free tier: Content may be used to improve Google products
   - Recommendation: Use paid tier for sensitive data (future)

3. **Error Messages**:
   - MUST sanitize error messages (no sensitive data)
   - MUST log only key names, never values
   - MUST redact email content in error logs

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2025-11-01 | Initial contract for Phase 1b (Gemini Entity Extraction MVP) |

---

**Contract Complete**: ✅
**Next Step**: Create quickstart.md with usage instructions
